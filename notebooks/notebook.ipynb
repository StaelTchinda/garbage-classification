{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7f8ffe3ef552485"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e41da93f89b7bc5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Text, Tuple\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import glob \n",
    "import matplotlib.pyplot as plotter\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.data.dataset import get_train_dataset, get_val_dataset, get_test_dataset, get_class_names\n",
    "from src.data.config import DATASET_PATH, get_default_dataset_config\n",
    "from src.model import get_model\n",
    "from src.utils import PROJECT_ROOT_PATH"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8707abbccc4b4580",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utility Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f291d0ca7d4cb6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_filenames_df():\n",
    "    files = [i for i in glob.glob(str(DATASET_PATH) + \"//*//*\")]\n",
    "    np.random.shuffle(files)\n",
    "    labels = [os.path.dirname(i).split(\"/\")[-1] for i in files]\n",
    "    data = zip(files, labels)\n",
    "    dataframe = pd.DataFrame(data, columns = [\"Image\", \"Label\"])\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "880b0f8d85d27ff",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display Functions   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc8f838ef7194b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_images(images: List[np.ndarray], subtitles: List[Text] = None, cols_count: int = 5, figsize: Tuple[int, int] = (20, 20)):\n",
    "    rows_count = math.ceil(len(images) / cols_count)\n",
    "    fig, axes = plt.subplots(rows_count, cols_count, figsize=figsize)\n",
    "    \n",
    "    if subtitles is not None and len(subtitles) != len(images):\n",
    "        raise ValueError(\"Number of images and subtitles should be equal\")\n",
    "    if subtitles is None:\n",
    "        subtitles = [\"\" for _ in range(len(images))]\n",
    "        \n",
    "    for image_idx in range(len(images)):\n",
    "        i, j = math.floor(image_idx / cols_count), image_idx % cols_count\n",
    "        if rows_count == 1:\n",
    "            ax = axes[j]\n",
    "        else:\n",
    "            ax = axes[i, j]\n",
    "\n",
    "        ax.imshow(images[image_idx])\n",
    "        ax.set_title(subtitles[image_idx])\n",
    "        ax.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de7339e881d1c96d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f61f448ba1f0dcd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fca5740c49518007"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataframe = get_filenames_df()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9945aab02e88db30",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mget_train_dataset\u001B[49m()\n\u001B[1;32m      2\u001B[0m val_data \u001B[38;5;241m=\u001B[39m get_val_dataset()\n\u001B[1;32m      3\u001B[0m test_data \u001B[38;5;241m=\u001B[39m get_test_dataset()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'get_train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = get_train_dataset()\n",
    "val_data = get_val_dataset()\n",
    "test_data = get_test_dataset()\n",
    "class_names = get_class_names()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T00:09:01.204928Z",
     "start_time": "2024-04-11T00:09:01.017563Z"
    }
   },
   "id": "2842bbef6166d197",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a65ee605345e44d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Display the distribution of the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d52546cef5c4469"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sns.countplot(x = dataframe[\"Label\"])\n",
    "plotter.xticks(rotation = 50);"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833a9dff4c962173",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Display some sample images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eefcaacbe2ee381"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "samples_per_class: int = 4\n",
    "\n",
    "class_samples = [train_data.unbatch().filter(lambda img, img_label: img_label == class_idx).take(samples_per_class) for class_idx in range(len(class_names))]\n",
    "\n",
    "images: List[np.ndarray] = []\n",
    "labels: List[Text] = []\n",
    "\n",
    "for samples in class_samples:\n",
    "    for imgs, label_indices in samples:\n",
    "        images.append(imgs.numpy().astype(\"uint8\"))\n",
    "        labels.append(class_names[label_indices.numpy() - 1])\n",
    "\n",
    "plot_images(images, labels, cols_count=4)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf03ca93045b62d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e152d5464fb21a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e233c6f6ac6887b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = get_model(class_count=len(class_names))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46f6c87883df49c4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "\n",
    "\n",
    "For training, please use the following command:\n",
    "```bash\n",
    "python -m scripts.train\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f74487159dfb0a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checkpoints\n",
    "\n",
    "Let's load the model from the last checkpoint and work on it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d6167b56837acc8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.trainer.config import TrainingConfig, get_default_training_config, ModelCheckpointConfig, CHECKPOINTS_PATH, get_default_checkpoint_path\n",
    "from src.data.config import  get_default_input_shape\n",
    "from src.trainer.eval import eval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b266519a3b84e6bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = get_model(class_count=len(class_names))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "515a928b2ecac3cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "config = get_default_training_config()\n",
    "checkpoint_path = get_default_checkpoint_path()\n",
    "input_shape = get_default_input_shape()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21dbb4236a08ce75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.build(input_shape=input_shape)\n",
    "model.load_weights(checkpoint_path)\n",
    "model.compile()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "885ea860b41c605b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ebf3368c67c188"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation on the validation set "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7308299d8a16071a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_result = eval(model, val_data)\n",
    "score = eval_result[0]\n",
    "metric_values = eval_result[1:]\n",
    "metrics = dict(zip(config.metrics, metric_values))\n",
    "print('Val Loss =', score)\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print(f\"Val {metric_name} = {metric_value}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e30f48bbe714dc89",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab65de44fd13499"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "samples_per_class: int = 2\n",
    "\n",
    "class_samples = [val_data.unbatch().filter(lambda img, img_label: img_label == class_idx).take(samples_per_class) for class_idx in range(len(class_names))]\n",
    "\n",
    "images: List[np.ndarray] = []\n",
    "labels: List[Text] = []\n",
    "\n",
    "for samples in class_samples:\n",
    "    for imgs, label_indices in samples:\n",
    "        images.append(imgs.numpy().astype(\"uint8\"))\n",
    "        labels.append(class_names[label_indices.numpy() - 1])\n",
    "\n",
    "predictions = model.predict(np.array(images))\n",
    "predicted_labels = [class_names[np.argmax(prediction)] for prediction in predictions]\n",
    "\n",
    "subtitles = [f\"True: {true_label}\\nPredicted: {predicted_label}\" for true_label, predicted_label in zip(labels, predicted_labels)]\n",
    "\n",
    "plot_images(images, subtitles, cols_count=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f834ddcef430908",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "434a2dcfcbc8f2b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b851a9b2739d7cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation on the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9705c41e173bb9c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_result = eval(model, test_data)\n",
    "score = eval_result[0]\n",
    "metric_values = eval_result[1:]\n",
    "metrics = dict(zip(config.metrics, metric_values))\n",
    "print('Test Loss =', score)\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print(f\"Test {metric_name} = {metric_value}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b712a1ccfc1fca0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d47e637647fcb5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X,y_true,y_pred=[],[],[]\n",
    "for images, labels in test_data:\n",
    "    y_true.extend(labels.numpy())\n",
    "    X.extend(images.numpy())\n",
    "predictions=model.predict(np.array(X))\n",
    "for i in predictions:\n",
    "    y_pred.append(np.argmax(i))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7050ec099eefa7f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9681256826586dd6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
